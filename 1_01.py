import numpy as np
import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, roc_auc_score
from sklearn.preprocessing import StandardScaler
from sklearn.utils import resample

# === 1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö ===

# –ó–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ –≤–∞—à–∏ —Ä–µ–∞–ª—å–Ω—ã–µ —Å–ø–∏—Å–∫–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
binary_features = [...]    # —Å–ø–∏—Å–æ–∫ –∫–æ–ª–æ–Ω–æ–∫ —Å 0/1
numeric_features = [...]   # —Å–ø–∏—Å–æ–∫ —á–∏—Å–ª–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
target = 'y'

# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
X_bin = df[binary_features]
X_num = df[numeric_features]
y = df[target]

# –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º —á–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
scaler = StandardScaler()
X_num_scaled = scaler.fit_transform(X_num)

# –û–±—ä–µ–¥–∏–Ω—è–µ–º –±–∏–Ω–∞—Ä–Ω—ã–µ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ —á–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
X_full = pd.concat([X_bin.reset_index(drop=True), 
                    pd.DataFrame(X_num_scaled, columns=numeric_features)], axis=1)

# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/test
X_train, X_test, y_train, y_test = train_test_split(X_full, y, test_size=0.3, random_state=42, stratify=y)

# === 2. –ú–æ–¥–µ–ª—å 1: LogisticRegression c class_weight='balanced' ===

model1 = LogisticRegression(solver='saga', penalty='l2', class_weight='balanced', max_iter=1000)
model1.fit(X_train, y_train)
y_pred1 = model1.predict(X_test)
y_proba1 = model1.predict_proba(X_test)[:, 1]

# === 3. –ú–æ–¥–µ–ª—å 2: Oversampling + –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –∏–Ω—Ç–µ—Ä—Å–µ–ø—Ç–∞ ===

# –°–æ–±–∏—Ä–∞–µ–º –¥–∞—Ç–∞—Ñ—Ä–µ–π–º –¥–ª—è oversampling
train_df = X_train.copy()
train_df['y'] = y_train.values

df_majority = train_df[train_df.y == 0]
df_minority = train_df[train_df.y == 1]

# Oversample –º–∏–Ω–æ—Ä–∏—Ç–∞—Ä–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∞ –¥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ majority
df_minority_over = resample(df_minority, 
                            replace=True, 
                            n_samples=len(df_majority), 
                            random_state=42)

df_balanced = pd.concat([df_majority, df_minority_over])
X_train_bal = df_balanced.drop(columns='y')
y_train_bal = df_balanced['y']

# –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å –Ω–∞ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
model2 = LogisticRegression(solver='saga', penalty='l2', max_iter=1000)
model2.fit(X_train_bal, y_train_bal)

# –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –∏–Ω—Ç–µ—Ä—Å–µ–ø—Ç–∞ –ø–æ —Ñ–æ—Ä–º—É–ª–µ Manski & Lerman
p = y_train.mean()   # —Ä–µ–∞–ª—å–Ω–∞—è –¥–æ–ª—è –∫–ª–∞—Å—Å–∞ 1 –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
r = 0.5              # –≤ oversampled –≤—ã–±–æ—Ä–∫–µ –∫–ª–∞—Å—Å 1 = 50%
b0_raw = model2.intercept_[0]
correction = np.log((p / r) * ((1 - r) / (1 - p)))
model2.intercept_ = np.array([b0_raw + correction])

# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
y_pred2 = model2.predict(X_test)
y_proba2 = model2.predict_proba(X_test)[:, 1]

# === 4. –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–µ–π ===

def evaluate_model(y_true, y_pred, y_proba, name):
    print(f"\nüìä {name}")
    print(classification_report(y_true, y_pred, digits=3))
    print(f"AUC ROC: {roc_auc_score(y_true, y_proba):.4f}")

evaluate_model(y_test, y_pred1, y_proba1, "–ú–æ–¥–µ–ª—å 1: class_weight='balanced'")
evaluate_model(y_test, y_pred2, y_proba2, "–ú–æ–¥–µ–ª—å 2: oversampling + –∏–Ω—Ç–µ—Ä—Å–µ–ø—Ç")


bins = [-np.inf, -500, -200, -100, -50, -10, 10, 50, 100, 200, 500, np.inf]
labels = [
    '—Ä–µ–∑–∫–æ–µ –ø–∞–¥–µ–Ω–∏–µ',
    '—Å–∏–ª—å–Ω–æ–µ –ø–∞–¥–µ–Ω–∏–µ',
    '–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–µ –ø–∞–¥–µ–Ω–∏–µ',
    '—É–º–µ—Ä–µ–Ω–Ω–æ–µ –ø–∞–¥–µ–Ω–∏–µ',
    '–ª—ë–≥–∫–æ–µ –ø–∞–¥–µ–Ω–∏–µ',
    '—Å—Ç–∞–±–∏–ª—å–Ω–æ',
    '–ª—ë–≥–∫–∏–π —Ä–æ—Å—Ç',
    '—É–º–µ—Ä–µ–Ω–Ω—ã–π —Ä–æ—Å—Ç',
    '–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–π —Ä–æ—Å—Ç',
    '—Å–∏–ª—å–Ω—ã–π —Ä–æ—Å—Ç',
    '—Ä–µ–∑–∫–∏–π —Ä–æ—Å—Ç'
]

# –ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è
df['delta_turnover_cat'] = pd.cut(df['delta_turnover'], bins=bins, labels=labels)

# –ü—Ä–æ–≤–µ—Ä–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
print(df['delta_turnover_cat'].value_counts().sort_index())

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(12, 5))
sns.countplot(data=df, x='delta_turnover_cat', order=labels)
plt.xticks(rotation=45)
plt.title("–ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è –æ–±–æ—Ä–æ—Ç–∞ (11 –≥—Ä—É–ø–ø)")
plt.xlabel("–ö–∞—Ç–µ–≥–æ—Ä–∏—è")
plt.ylabel("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∏–µ–Ω—Ç–æ–≤")
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns

# –°–ø–∏—Å–æ–∫ –ø—Ä–æ—Ü–µ–Ω—Ç–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
percent_features = ['delta_turnover', 'change_in_spending', 'margin_change']  # –ø—Ä–∏–º–µ—Ä—ã

# –¶–∏–∫–ª –ø–æ —Ñ–∏—á–∞–º
for feature in percent_features:
    plt.figure(figsize=(14, 5))

    # –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞
    plt.subplot(1, 2, 1)
    sns.histplot(df[feature], bins=100, kde=True)
    plt.title(f"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ: {feature}")
    plt.xlabel("–ó–Ω–∞—á–µ–Ω–∏–µ (%)")
    plt.ylabel("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ")

    # Boxplot (–≤—ã–±—Ä–æ—Å—ã)
    plt.subplot(1, 2, 2)
    sns.boxplot(x=df[feature])
    plt.title(f"Boxplot: {feature}")

    plt.tight_layout()
    plt.show()

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø—Ä–∏–∑–Ω–∞–∫—É: {feature}")
    print(df[feature].describe(percentiles=[.01, .05, .25, .5, .75, .95, .99]))
    print("-" * 80)
